---
title: "OLS and MLE"
author: "BIOS 620"
date: "3/4/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Example dataset `mtcars`

```{r}
data("mtcars")
head(mtcars)
```

## Simple linear Regression

```{r}
fit1 <- lm(mpg ~ qsec, mtcars)
summary(fit1)
```

## Draw a scatterplot

```{r}
with(mtcars, plot(qsec, mpg))
```

## Predicted values from the regression (yhat)

```{r}
yhat0 <- predict(fit1)
yhat1 <- fitted(fit1)
yhat2 <- coef(fit1)[1] + coef(fit1)[2] * mtcars$qsec

hatdf <- data.frame(yhat0, yhat1, yhat2)
head(hatdf)
```

## Adding a regression line to our scatterplot

```{r}
with(mtcars, plot(qsec, mpg))
lines(mtcars$qsec, yhat0, col = "yellow", lty = 3, lwd = 3)
abline(fit1, col = "green", lty = 2)
```

## Manual calculation of TSS, RegSS, and ESS

```{r}
y_mean <- mean(mtcars$mpg)
y_mean
```

```{r}
TSS <- sum((mtcars$mpg - y_mean)^2)
TSS
```

```{r}
RegSS <- sum((yhat0 - y_mean)^2)
```

```{r}
ESS <- sum((mtcars$mpg - yhat0)^2)
```

```{r}
RegSS + ESS 
```

# Manually calculate the coefficients 

\[
\begin{split}
   \hat{\beta}_{1} &= \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i} - \bar{y})}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2} \\
   \hat{\beta}_{0} &= \bar{y} - \hat{\beta}_{1} \bar{x}.\\
\end{split}
\]

```{r}
x_mean <- mean(mtcars$qsec)
```

```{r}
x <- mtcars$qsec
y <- mtcars$mpg
beta1 <- sum ((x - x_mean) * (y - y_mean)) / sum ((x - x_mean)^2 )
```

```{r}
beta0 <- y_mean - (beta1 * x_mean)
```

```{r}
coef(fit1)
```

```{r}
beta0
beta1
```

# Maximum Likelihood Estimation

See these links for digestible explanations of the method:

https://alemorales.info/post/mle-nonlinear/

https://rpsychologist.com/likelihood/

# Lab 5 (empirically prove formula and equation)

Fit a regression with only 1 covariate (either by simulation or real data).

* Fit a linear regression model to obtain the regression coefficients (intercept
and slope) by using lm() function.

* Manually calculate the coefficients using the formula below and compare with
the model's output

\[
\begin{split}
   \hat{\beta}_{1} &= \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i} - \bar{y})}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2} \\
   \hat{\beta}_{0} &= \bar{y} - \hat{\beta}_{1} \bar{x}.\\
\end{split}
\]

* Calculate the
LHS (left hand side) of following equation to see if the resulting numerical
value is close to zero.

\[
  \sum_{i=1}^{n} (\hat{y}_{i} - \bar{y})(y_{i} - \hat{y}_{i}) = 0.
\]